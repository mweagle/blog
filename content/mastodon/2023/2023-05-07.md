---
title: "Mastodon - 2023-05-07"
description: ""
image: "/images/mastodon.png"
date: 2023-05-07T00:00:00Z
lastmod: 2023-05-07T00:00:00Z
tags: ["Social Media"]
categories: ["mastodon"]
# generated: 2025-10-05T17:59:09-07:00
---

# Toots from 2023-05-07

## [@marcolodola](https://mastodon.uno/@marcolodola) And it puts the person in an impossible position.

[@marcolodola](https://mastodon.uno/@marcolodola) And it puts the person in an impossible position.

##### [Mastodon Source ğŸ˜](https://hachyderm.io/@mweagle/110328114008622700)

---

## â€œThis is the autopilot problem: How do you know when the computer is giving you a wrong answer?...

â€œThis is the autopilot problem: How do you know when the computer is giving you a wrong answer? Ideally, you know because you have enough experience to know what the right answer looks like, but this assumes you are paying attention to the answer youâ€™ve been given.â€

<https://public.milcyber.org/activities/magazine/articles/2023/draeger-the-autopilot-problem>

##### [Mastodon Source ğŸ˜](https://hachyderm.io/@mweagle/110325905521930489)

---

## â€œThe Prime Video team had followed a path I call Serverless First, where the first try at build...

â€œThe Prime Video team had followed a path I call Serverless First, where the first try at building something is put together with Step Functions and Lambda calls. They state in the blog that this was quick to build, which is the pointâ€¦In contrast to commentary along the lines that Amazon got it wrong, the team followed what I consider to be the best practice.â€

<https://adrianco.medium.com/so-many-bad-takes-what-is-there-to-learn-from-the-prime-video-microservices-to-monolith-story-4bd0970423d4>

##### [Mastodon Source ğŸ˜](https://hachyderm.io/@mweagle/110325592519041827)

---

## This paper is full of wisdom. A selection of quotes that are as pertinent today as they were 40 y...

This paper is full of wisdom. A selection of quotes that are as pertinent today as they were 40 years ago.

â€œWhen I pointed this out to engineers their response then was people should just pay attention to all alarms regardless. When I heard developers say people should just be more careful, I knew that statement was an indicator of the design of a bad human-machine system. â€œ

##### [Mastodon Source ğŸ˜](https://hachyderm.io/@mweagle/110325556194652484)

â€œMeanwhile it is still popular to build either/or architectures where the machine does all the work and people are supposed to monitor the machine to jump in when it is doing the wrong thing. Orâ€¦the machine does all the work till it can no longer, and then it dumps the messy situation into some humanâ€™s handsâ€”bumpy transfers of control. With every either/or architecture comes new opportunities to observe the same unintended and undesirable effects as I observed in the mid-1980â€™sâ€

##### [Mastodon Source ğŸ˜](https://hachyderm.io/@mweagle/110325567176178702)

â€œBy the way, when it comes to all things AI, remember there is always a hidden trick â€” good CSE-ers find ways to break automata and plans by focusing on patterns of demands that challenge any agent or set of agents whatever the combination of human and machine roles.â€œ

##### [Mastodon Source ğŸ˜](https://hachyderm.io/@mweagle/110325570484299567)

D Woods, David. 2016. â€œOrigins of Cognitive Systems Engineering.â€ 2016. <https://www.researchgate.net/publication/298793082_Origins_of_Cognitive_Systems_Engineering>.

##### [Mastodon Source ğŸ˜](https://hachyderm.io/@mweagle/110325572401806126)

---

