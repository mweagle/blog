---
title: "Mastodon - 2024-11-20T06:34:07Z"
subtitle: ""
canonical: https://hachyderm.io/users/mweagle/statuses/113513886337695806
description:
image: "/images/mastodon.png"

date: 2024-11-20T06:34:07Z
lastmod: 2024-11-20T06:34:07Z
image: ""
tags: ["Social Media"]

categories: ["mastodon"]
# generated: 2025-05-22T22:29:20-07:00
---
![Mastodon](/images/mastodon.png)

<p>“So this entire process, in order to add “what is 2+2”, we do a non-deterministic a lookup from an enormous hashtable that contains the sum of public human knowledge we’ve seen fit to collect for our dataset, then we squeeze it through the tiny, nondeterministic funnels of decoding strategies and guided generation to get to an answer from a sampled probability distribution.”</p><p><a href="https://newsletter.vickiboykis.com/archive/why-are-we-using-llms-as-calculators/" target="_blank" rel="nofollow noopener noreferrer" translate="no"><span class="invisible">https://</span><span class="ellipsis">newsletter.vickiboykis.com/arc</span><span class="invisible">hive/why-are-we-using-llms-as-calculators/</span></a></p>


###### [Mastodon Source 🐘](https://hachyderm.io/@mweagle/113513886337695806)

___

<p>“We hypothesize that this decline is due to the fact that current LLMs are not capable of genuine logical reasoning; instead, they attempt to replicate the reasoning steps observed in their training data. When we add a single clause that appears relevant to the question, we observe significant performance drops (up to 65%) across all state-of-the-art models, even though the added clause does not contribute to the reasoning chain needed to reach the final answer” </p><p><a href="https://arxiv.org/abs/2410.05229" target="_blank" rel="nofollow noopener noreferrer" translate="no"><span class="invisible">https://</span><span class="">arxiv.org/abs/2410.05229</span><span class="invisible"></span></a></p>


###### [Mastodon Source 🐘](https://hachyderm.io/@mweagle/113513896908279852)

___
