---
title: "Mastodon - 2024-12-05T06:27:48Z"
subtitle: ""
canonical: https://hachyderm.io/users/mweagle/statuses/113598796167342147
description:
image: "/images/mastodon.png"

date: 2024-12-05T06:27:48Z
lastmod: 2024-12-05T06:27:48Z
image: ""
tags: ["Social Media"]

categories: ["mastodon"]
# generated: 2025-03-16T12:33:30-04:00
---
![Mastodon](/images/mastodon.png)

<p>Biased evaluations aren’t a deviation from expected behavior. They are expected. How did they initially confirm this AI was safe to deploy? It&#39;s misleading to label this an incident. <br /> <br />&quot;It can take weeks or even months to fully understand the source of an AI incident. One client had no such plan when it discovered that an AI-based HR screening tool used to assess job applicants was giving preferential treatment to a specific demographic group.”</p><p><a href="https://hbr.org/2024/12/how-to-prepare-your-company-for-ai-incidents" target="_blank" rel="nofollow noopener noreferrer" translate="no"><span class="invisible">https://</span><span class="ellipsis">hbr.org/2024/12/how-to-prepare</span><span class="invisible">-your-company-for-ai-incidents</span></a></p>


###### [Mastodon Source 🐘](https://hachyderm.io/@mweagle/113598796167342147)

___

<p>&quot;Shortly after it had deployed a generative AI system, one client learned that the system had been trained on huge amounts of problematic data — including copyrighted materials and personal data that had been collected without users’ consent.”</p><p>These are organizational learning opportunities surfaced by shipping software. The specific type of software is incidental.</p>


###### [Mastodon Source 🐘](https://hachyderm.io/@mweagle/113598837001547766)

___
